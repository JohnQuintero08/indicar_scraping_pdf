{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(script, text):\n",
    "    return re.search(script, text).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_header(page):\n",
    "    text = page.extract_text()\n",
    "    event = extract_text(r'Event:\\s*(.*?)\\s*Round', text)\n",
    "    round= extract_text(r'Round\\s*(.*?)\\s*Track', text)\n",
    "    track = extract_text(r'Track:\\s*(.*?)\\s*Report', text)\n",
    "    report = extract_text(r'Report:\\s*(.*?)\\s*Session', text)\n",
    "    session = extract_text(r'Session:\\s*(.*?)\\s*\\n', text)\n",
    "    car, driver = extract_text(r'Car\\s*(.*?)\\s*\\n', text).split('-')\n",
    "    return event, round, track, report, session, car, driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table(page):\n",
    "    table = np.array(page.extract_table())\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_header(header):\n",
    "    event, round, track, report, session, car, driver = header\n",
    "    result = f\"\"\"\n",
    "    Event: {event}\n",
    "    Round: {round}\n",
    "    Track: {track}\n",
    "    Report: {report}\n",
    "    Session: {session}\n",
    "    Car: {car}\n",
    "    Driver: {driver}\n",
    "    \"\"\"\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_array(size, param):\n",
    "    return np.full(size, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lap_correction(lap_list):\n",
    "    new_list = []\n",
    "    for i in range(len(lap_list)):\n",
    "        j = lap_list.iloc[i]  \n",
    "        if i == 0:\n",
    "            valor = j\n",
    "        elif i % 2 == 1:\n",
    "            valor = lap_list.iloc[i-1]  \n",
    "        else:\n",
    "            valor = j  \n",
    "        new_list.append(valor)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_correction(df):\n",
    "    df['Lap'] = lap_correction(df['Lap'])\n",
    "    df = df.replace('', np.nan)\n",
    "    \n",
    "    integer_columns = ['car','Lap']\n",
    "    float_columns = ['SF_to_T1', 'T1_to_SS1', 'SS1_to_T2', 'T2_to_BS', 'BS_to_T3', 'T3_to_SS2', 'SS2_to_T4', 'T4_to_FS', 'FS_to_SF', 'Lapt', 'PI_to_PO', 'PO_to_SF', 'SF_to_PI']\n",
    "    for col in integer_columns:\n",
    "        df[col] = df[col].astype(int)\n",
    "    for col in float_columns:\n",
    "        df[col] = df[col].astype(float)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_page(page):\n",
    "    header = extract_header(page)\n",
    "    table = extract_table(page) \n",
    "    headers_table = ['Lap', 'T/S', 'SF_to_T1', 'T1_to_SS1', 'SS1_to_T2', 'T2_to_BS', 'BS_to_T3', 'T3_to_SS2', 'SS2_to_T4', 'T4_to_FS', 'FS_to_SF', 'Lapt', 'PI_to_PO', 'PO_to_SF', 'SF_to_PI']\n",
    "    shape_table = np.shape(table)[0]\n",
    "    event, round, track, report, session, car, driver = header\n",
    "    \n",
    "    event_arr = full_array(shape_table, event)\n",
    "    round_arr = full_array(shape_table, round)\n",
    "    track_arr = full_array(shape_table, track)\n",
    "    report_arr = full_array(shape_table, report)\n",
    "    session_arr = full_array(shape_table, session)\n",
    "    car_arr = full_array(shape_table, car)\n",
    "    driver_arr = full_array(shape_table, driver)\n",
    "    \n",
    "    data = {'event': event_arr,\n",
    "            'round': round_arr,\n",
    "            'track': track_arr,\n",
    "            'report': report_arr,\n",
    "            'session': session_arr,\n",
    "            'car': car_arr,\n",
    "            'driver': driver_arr}\n",
    "    \n",
    "    df_header = pd.DataFrame(data)\n",
    "    df_table = pd.DataFrame(table, columns=headers_table)\n",
    "    df_page = pd.concat([df_header, df_table], axis=1)\n",
    "    \n",
    "    df_page_corrected = table_correction(df_page)\n",
    "    \n",
    "    return df_page_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_pages(pdf):\n",
    "    base_df = create_df_page(pdf.pages[0])\n",
    "    for page in range(1, len(pdf.pages)):\n",
    "        print(f'Reading page {page}')\n",
    "        try:\n",
    "            new_df = create_df_page(pdf.pages[page])\n",
    "            base_df = pd.concat([base_df, new_df], axis=0).reset_index(drop=True)\n",
    "        except:\n",
    "            print(f'Page # {page+1} was not read it has different content to the format')\n",
    "            continue\n",
    "    print('No more pages to read ... we are done')\n",
    "    return base_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_save_dataset(route):\n",
    "    new_datasets_route = 'new_datasets/'\n",
    "    # Check and creates the directory if it does not exist\n",
    "    os.makedirs(new_datasets_route, exist_ok=True)\n",
    "    try:\n",
    "        \n",
    "        pdf_files = [file for file in os.listdir(route) if file.lower().endswith(\".pdf\")]\n",
    "\n",
    "        if not pdf_files:\n",
    "            raise FileNotFoundError(f\"The folder {route} does not have any pdf file to read\")\n",
    "\n",
    "        for file in os.listdir(route):\n",
    "            if file.lower().endswith(\".pdf\"):\n",
    "                route_pdf = os.path.join(route, file)\n",
    "                print(f\"ðŸ“– Reading: {file}, Route: {route_pdf}\")\n",
    "                pdf =  pdfplumber.open(f'{route_pdf}')\n",
    "                whole_pdf = read_all_pages(pdf)\n",
    "                name_file = file.replace('.pdf',\"\")\n",
    "                route_new_dataset = os.path.join(new_datasets_route, f'{name_file}.parquet')\n",
    "                whole_pdf.to_parquet(route_new_dataset, index=False)\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: [WinError 123] El nombre de archivo, el nombre de directorio o la sintaxis de la etiqueta del volumen no son correctos: '--f=c:\\\\Users\\\\Gamer2022\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v368931657b6c357121e6c8c2cbed43ed0bd1ddec2.json'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) < 2:\n",
    "        print(\"Error: You must provide a folder path with PDFs\")\n",
    "        sys.exit(1)  \n",
    "    route_pdfs = sys.argv[1] \n",
    "    read_and_save_dataset(route_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_save_dataset(route):\n",
    "    new_datasets_route = './new_datasets/'\n",
    "    # Checks and creates the directory if it does not exist\n",
    "    os.makedirs(new_datasets_route, exist_ok=True)\n",
    "\n",
    "    for file in os.listdir(route):\n",
    "        if file.lower().endswith(\".pdf\"):\n",
    "            # Route for reading the files\n",
    "            route_pdf = os.path.join(route, file)\n",
    "            print(f\"ðŸ“– Reading: {file}, Route: {route_pdf}\")\n",
    "            # Read the pages\n",
    "            pdf = pdfplumber.open(f'{route_pdf}')\n",
    "            whole_pdf = read_all_pages(pdf)\n",
    "            # Save the dataset created in the new_datasets folder\n",
    "            name_file = file.replace('.pdf', \"\")\n",
    "            route_new_dataset = os.path.join(\n",
    "                new_datasets_route, f'{name_file}.parquet')\n",
    "            whole_pdf.to_parquet(route_new_dataset, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
