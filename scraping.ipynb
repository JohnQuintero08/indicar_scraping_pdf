{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(script, text):\n",
    "    return re.search(script, text).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_header(page):\n",
    "    text = page.extract_text()\n",
    "    event = extract_text(r'Event:\\s*(.*?)\\s*Round', text)\n",
    "    round= extract_text(r'Round\\s*(.*?)\\s*Track', text)\n",
    "    track = extract_text(r'Track:\\s*(.*?)\\s*Report', text)\n",
    "    report = extract_text(r'Report:\\s*(.*?)\\s*Session', text)\n",
    "    session = extract_text(r'Session:\\s*(.*?)\\s*\\n', text)\n",
    "    car, driver = extract_text(r'Car\\s*(.*?)\\s*\\n', text).split('-')\n",
    "    return event, round, track, report, session, car, driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table(page):\n",
    "    table = np.array(page.extract_table())\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_header(header):\n",
    "    event, round, track, report, session, car, driver = header\n",
    "    result = f\"\"\"\n",
    "    Event: {event}\n",
    "    Round: {round}\n",
    "    Track: {track}\n",
    "    Report: {report}\n",
    "    Session: {session}\n",
    "    Car: {car}\n",
    "    Driver: {driver}\n",
    "    \"\"\"\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_array(size, param):\n",
    "    return np.full(size, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lap_correction(lap_list):\n",
    "    new_list = []\n",
    "    for i in range(len(lap_list)):\n",
    "        j = lap_list.iloc[i]  \n",
    "        if i == 0:\n",
    "            valor = j\n",
    "        elif i % 2 == 1:\n",
    "            valor = lap_list.iloc[i-1]  \n",
    "        else:\n",
    "            valor = j  \n",
    "        new_list.append(valor)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_correction(df):\n",
    "    df['Lap'] = lap_correction(df['Lap'])\n",
    "    df = df.replace('', np.nan)\n",
    "    \n",
    "    integer_columns = ['car','Lap']\n",
    "    float_columns = ['SF_to_T1', 'T1_to_SS1', 'SS1_to_T2', 'T2_to_BS', 'BS_to_T3', 'T3_to_SS2', 'SS2_to_T4', 'T4_to_FS', 'FS_to_SF', 'Lapt', 'PI_to_PO', 'PO_to_SF', 'SF_to_PI']\n",
    "    for col in integer_columns:\n",
    "        df[col] = df[col].astype(int)\n",
    "    for col in float_columns:\n",
    "        df[col] = df[col].astype(float)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_page(page):\n",
    "    header = extract_header(page)\n",
    "    table = extract_table(page) \n",
    "    headers_table = ['Lap', 'T/S', 'SF_to_T1', 'T1_to_SS1', 'SS1_to_T2', 'T2_to_BS', 'BS_to_T3', 'T3_to_SS2', 'SS2_to_T4', 'T4_to_FS', 'FS_to_SF', 'Lapt', 'PI_to_PO', 'PO_to_SF', 'SF_to_PI']\n",
    "    shape_table = np.shape(table)[0]\n",
    "    event, round, track, report, session, car, driver = header\n",
    "    \n",
    "    event_arr = full_array(shape_table, event)\n",
    "    round_arr = full_array(shape_table, round)\n",
    "    track_arr = full_array(shape_table, track)\n",
    "    report_arr = full_array(shape_table, report)\n",
    "    session_arr = full_array(shape_table, session)\n",
    "    car_arr = full_array(shape_table, car)\n",
    "    driver_arr = full_array(shape_table, driver)\n",
    "    \n",
    "    data = {'event': event_arr,\n",
    "            'round': round_arr,\n",
    "            'track': track_arr,\n",
    "            'report': report_arr,\n",
    "            'session': session_arr,\n",
    "            'car': car_arr,\n",
    "            'driver': driver_arr}\n",
    "    \n",
    "    df_header = pd.DataFrame(data)\n",
    "    df_table = pd.DataFrame(table, columns=headers_table)\n",
    "    df_page = pd.concat([df_header, df_table], axis=1)\n",
    "    \n",
    "    df_page_corrected = table_correction(df_page)\n",
    "    \n",
    "    return df_page_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_pages(pdf):\n",
    "    base_df = create_df_page(pdf.pages[0])\n",
    "    for page in range(1, len(pdf.pages)):\n",
    "        print(f'Reading page {page}')\n",
    "        try:\n",
    "            new_df = create_df_page(pdf.pages[page])\n",
    "            base_df = pd.concat([base_df, new_df], axis=0).reset_index(drop=True)\n",
    "        except:\n",
    "            print(f'Page # {page+1} was not read it has different content to the format')\n",
    "            continue\n",
    "    print('No more pages to read ... we are done')\n",
    "    return base_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_save_dataset(route):\n",
    "    new_datasets_route = 'new_datasets/'\n",
    "    # Check and creates the directory if it does not exist\n",
    "    os.makedirs(new_datasets_route, exist_ok=True)\n",
    "    \n",
    "    for file in os.listdir(route):\n",
    "        if file.lower().endswith(\".pdf\"):\n",
    "            route_pdf = os.path.join(route, file)\n",
    "            print(f\"ðŸ“– Reading: {file}, Route: {route_pdf}\")\n",
    "        pdf =  pdfplumber.open(f'{route_pdf}')\n",
    "        whole_pdf = read_all_pages(pdf)\n",
    "        #### ARREGLAR LA RUTA DE ACCESO PARA GUARDAR LOS ARCHIVOS\n",
    "        route = os.path.join(new_datasets_route, f'{file}.parquet')\n",
    "        whole_pdf.to_parquet(route, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“– Reading: doc_1_14_21.pdf, Route: pdfs/doc_1_14_21.pdf\n",
      "Reading page 1\n",
      "Reading page 2\n",
      "Reading page 3\n",
      "Reading page 4\n",
      "Reading page 5\n",
      "Reading page 6\n",
      "Reading page 7\n",
      "No more pages to read ... we are done\n",
      "ðŸ“– Reading: doc_1_1_13.pdf, Route: new_datasets/doc_1_14_21.pdf.parquet\\doc_1_1_13.pdf\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'new_datasets/doc_1_14_21.pdf.parquet\\\\doc_1_1_13.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mread_and_save_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpdfs/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 10\u001b[0m, in \u001b[0;36mread_and_save_dataset\u001b[1;34m(route)\u001b[0m\n\u001b[0;32m      8\u001b[0m     route_pdf \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(route, file)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ“– Reading: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Route: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroute_pdf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m pdf \u001b[38;5;241m=\u001b[39m  \u001b[43mpdfplumber\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mroute_pdf\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m whole_pdf \u001b[38;5;241m=\u001b[39m read_all_pages(pdf)\n\u001b[0;32m     12\u001b[0m route \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(new_datasets_route, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Gamer2022\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pdfplumber\\pdf.py:95\u001b[0m, in \u001b[0;36mPDF.open\u001b[1;34m(cls, path_or_fp, pages, laparams, password, strict_metadata, unicode_norm, repair, gs_path, repair_setting, raise_unicode_errors)\u001b[0m\n\u001b[0;32m     93\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_fp, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath)):\n\u001b[1;32m---> 95\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath_or_fp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     stream_is_external \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(path_or_fp)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'new_datasets/doc_1_14_21.pdf.parquet\\\\doc_1_1_13.pdf'"
     ]
    }
   ],
   "source": [
    "read_and_save_dataset('pdfs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf =  pdfplumber.open('pdfs/doc_1_1_13.pdf')\n",
    "# whole_pdf = read_all_pages(pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
